{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0adaa53c",
   "metadata": {},
   "source": [
    "#### Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd3f9ab",
   "metadata": {},
   "source": [
    "Download the YOLOv3 weights file (yolov3.weights), configuration file (yolov3.cfg), and class names file (coco.names) from the official YOLO website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee099c23",
   "metadata": {},
   "source": [
    "#### yolov3.weights:\n",
    "\n",
    "This file contains the pre-trained weights of the YOLOv3 model.\n",
    "\n",
    "The weights represent the learned parameters from the model during training on a large dataset. \n",
    "\n",
    "The YOLOv3 weights file is quite large, and it encapsulates the knowledge acquired by the model to recognize a wide range of objects.\n",
    "\n",
    "The weights file provides the learned parameters of the model, enabling it to make accurate predictions based on the features it learned during training.\n",
    "\n",
    "The weights file in the context of neural networks, including YOLOv3, contains the learned parameters of the model. \n",
    "\n",
    "These parameters represent the weights and biases of the network's neurons, and they have been adjusted during the training process to minimize the difference between the predicted output and the actual output (ground truth) for a given input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbceb5ee",
   "metadata": {},
   "source": [
    "#### yolov3.cfg:\n",
    "\n",
    "The configuration file specifies the architecture and configuration settings of the YOLOv3 model. \n",
    "\n",
    "It defines parameters such as the number of layers, filter sizes, activation functions, and more. \n",
    "\n",
    "The configuration file is crucial for reconstructing the YOLOv3 model architecture, allowing you to load the model correctly in your code.\n",
    "\n",
    "The configuration file is needed to reconstruct the YOLOv3 model architecture correctly in your code. \n",
    "\n",
    "It specifies the number of layers, their types, and various hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fae12be",
   "metadata": {},
   "source": [
    "#### coco.names:\n",
    "\n",
    "The class names file contains a list of object classes that the YOLOv3 model has been trained to detect.\n",
    "\n",
    "In the case of the coco.names file, it includes names of objects from the COCO (Common Objects in Context) dataset, which is a widely used dataset for object detection. \n",
    "\n",
    "Each line in the file corresponds to a unique object class.\n",
    "\n",
    "The class names file helps you interpret the output of the model. \n",
    "\n",
    "It provides the names of the classes corresponding to the numeric labels predicted by the model. This is crucial for understanding which objects the model has detected in an image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a53a63",
   "metadata": {},
   "source": [
    "Together, these files allow you to use a pre-trained YOLOv3 model for object detection tasks without having to train the model from scratch on your specific dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d55cab53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T11:40:00.480396Z",
     "start_time": "2024-01-30T11:39:59.635981Z"
    }
   },
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d7855ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T11:40:01.524205Z",
     "start_time": "2024-01-30T11:40:00.486379Z"
    }
   },
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "classes = []\n",
    "\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f]\n",
    "\n",
    "layer_names = net.getUnconnectedOutLayersNames()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c02563",
   "metadata": {},
   "source": [
    "Use cv2.dnn.readNet to load the YOLO model from the weights and configuration files.\n",
    "Read class names from the coco.names file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcb4c1e",
   "metadata": {},
   "source": [
    "layer_names = net.getUnconnectedOutLayersNames() is used to retrieve the names of the unconnected output layers of the YOLOv3 neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b2f511",
   "metadata": {},
   "source": [
    "getUnconnectedOutLayersNames(): This method is provided by OpenCV's DNN module, specifically for YOLO models. It returns the names of the unconnected output layers.\n",
    "\n",
    "In YOLOv3, the network architecture is designed in such a way that the final detection results are obtained from multiple output layers. These output layers provide predictions at different scales or resolutions.\n",
    "\n",
    "The output layers of the YOLOv3 network are unconnected because they operate independently and provide predictions for different spatial resolutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7de5c6a",
   "metadata": {},
   "source": [
    "In summary, layer_names = net.getUnconnectedOutLayersNames() is used to obtain the names of the unconnected output layers of the YOLOv3 model, which is important for extracting detection results during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34508de8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T11:40:01.555124Z",
     "start_time": "2024-01-30T11:40:01.536173Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to get object predictions\n",
    "def get_predictions(img):\n",
    "    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(layer_names)\n",
    "\n",
    "    return outs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7e6c93",
   "metadata": {},
   "source": [
    "This code defines a function get_predictions that takes an input image (img) and performs object detection using a YOLOv3 neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74125138",
   "metadata": {},
   "source": [
    "cv2.dnn.blobFromImage: This function preprocesses the input image to make it suitable for input to the YOLOv3 network. The parameters used are as follows:\n",
    "\n",
    "img: The input image.\n",
    "0.00392: Scaling factor for pixel values. This is used to normalize the pixel values.\n",
    "\n",
    "(416, 416): Size to which the image will be resized before feeding it to the network. YOLOv3 typically uses 416x416 pixels.\n",
    "\n",
    "(0, 0, 0): Mean subtraction values for each channel (BGR).\n",
    "\n",
    "True: Indicates whether to swap the Blue and Red channels, which is typically set to True for OpenCV.\n",
    "\n",
    "crop=False: Indicates whether to crop the image after resizing.\n",
    "\n",
    "The resulting blob is a standardized input that can be fed into the YOLOv3 network.\n",
    "\n",
    "net.setInput(blob): This sets the blob as the input to the YOLOv3 network. The neural network is now ready to perform a forward pass with this input.\n",
    "\n",
    "net.forward(layer_names): This is the forward pass through the YOLOv3 network. It computes the output of the network based on the given input blob. The layer_names are the names of the unconnected output layers, and they were obtained earlier using net.getUnconnectedOutLayersNames().\n",
    "\n",
    "return outs: The variable outs contains the predictions made by the YOLOv3 network. These predictions include information about bounding boxes, class probabilities, and other relevant details for detected objects.\n",
    "\n",
    "By calling get_predictions on an input image, you obtain the YOLOv3 predictions, which can be further processed to draw bounding boxes, display confidence scores, and interpret the detected objects in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47fba83f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T11:40:02.068776Z",
     "start_time": "2024-01-30T11:40:01.564099Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to draw bounding boxes\n",
    "def draw_boxes(img, outs):\n",
    "    height, width, _ = img.shape\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    #This parts iterates the output model\n",
    "    #THe yolov3 model divides the inputs image into\n",
    "    #a grid and ,akes predictions for each grid cell\n",
    "\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            #For each detection in the grid cell, this part extracts the confidence\n",
    "            #Scores for each class\n",
    "            #The class_id is detemined as the index with the maximum confidence\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            #It checks if the confidence for the predicted class is above threshold\n",
    "            #Certain threshold(e.g, 0.5)\n",
    "            #If the confidence is below this threshold, the detection is ignored\n",
    "            \n",
    "            if confidence > 0.5:\n",
    "            #This calculates the bounding box co-ordinates and dimensions using\n",
    "            #The information from YOLO output\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "               #The relevent info (class id,confidence,and boundong box)\n",
    "               #is append to lists for further processing\n",
    "\n",
    "                class_ids.append(class_id)\n",
    "                confidences.append(float(confidence))\n",
    "                boxes.append([x, y, w, h])\n",
    "     #non-maximum suppression is applied to eliminate redunant and overlapping boxes.\n",
    "    #It keeps only the most confident bounding boxes\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "    # Loop through the indices after non-maximum suppression\n",
    "    for i in indices:\n",
    "        # i is already a scalar, so no need to use i[0]\n",
    "        box = boxes[i]\n",
    "        x, y, w, h = box\n",
    "\n",
    "        # Get class label, confidence, and color for drawing the bounding box\n",
    "        label = str(classes[class_ids[i]])\n",
    "        confidence = confidences[i]\n",
    "        color = (0, 255, 0)  # Green color\n",
    "\n",
    "        # Draw bounding box and label on the image\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
    "        cv2.putText(img, f\"{label} {confidence:.2f}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719d1f40",
   "metadata": {},
   "source": [
    "This code defines a function draw_boxes that takes an input image (img) and the output of YOLOv3 predictions (outs). The function processes the predictions and draws bounding boxes around detected objects on the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41068ca",
   "metadata": {},
   "source": [
    "Loop through detections: The function iterates through the detections provided by the YOLOv3 output and extracts relevant information such as class IDs, confidences, and bounding box coordinates.\n",
    "\n",
    "Filter by confidence: Detections with confidence scores below a certain threshold (e.g., 0.5) are ignored.\n",
    "\n",
    "Calculate bounding box coordinates: The function calculates the bounding box coordinates based on the YOLOv3 output.\n",
    "\n",
    "Non-maximum suppression: Non-maximum suppression (NMS) is applied to eliminate redundant overlapping boxes, keeping only the most confident ones.\n",
    "\n",
    "Draw bounding boxes: The function then draws bounding boxes and labels on the input image using OpenCV functions.\n",
    "\n",
    "Overall, the draw_boxes function facilitates the visualization of YOLOv3 object detection results by drawing bounding boxes around detected objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a211d24b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T11:40:02.723308Z",
     "start_time": "2024-01-30T11:40:02.071740Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read input image\n",
    "img = cv2.imread(\"planet1.jpeg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16df956b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T11:40:05.326137Z",
     "start_time": "2024-01-30T11:40:02.727304Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get YOLO predictions\n",
    "outs = get_predictions(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d780ce5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T11:40:05.467813Z",
     "start_time": "2024-01-30T11:40:05.334123Z"
    }
   },
   "outputs": [],
   "source": [
    "# Draw bounding boxes on the image\n",
    "draw_boxes(img, outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "584467f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T11:40:42.901034Z",
     "start_time": "2024-01-30T11:40:05.476779Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display the output image\n",
    "cv2.imshow(\"YOLO Object Detection\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635696ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
